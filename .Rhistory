data <- remove.dict(data)
data <- assign.dict(data, get.dict(data))
dict_data <- get.dict(data) # get a dictionary for this data
dict_data$type[which(dict_data$varname=="VitalID")] <- "key"
dict_data$unique_per_sbj[which(dict_data$varname=="VitalID")] <- TRUE
rownames(dict_data) <- NULL
new_data <- data
new_dict_data <- dict_data
# median imputed
# Perform median imputation
for (var_name in names(median_ls)) {
if (var_name %in% names(new_data)) {
# Replace NA in new_data with the median value from median_values
new_data[[var_name]][is.na(new_data[[var_name]])] <- median_ls[[var_name]]
}
}
test_y <- rms::predictrms(model_obj, newdata = new_data)
write.csv( data.frame(p = 1/(1+exp(-test_y))), paste0(res_dir,"/test_p.csv"),row.names = F)
print(cvAUC)
knitr::opts_chunk$set(root.dir="/Users/joyqiu/Documents/Documents JoyQiu Work/Research/NIC/case/pas",
error=FALSE,
collapse = FALSE,
echo = TRUE,
warning = FALSE,
message = FALSE,
results = FALSE,
fig.dim= c(10,5)
)
library(dplyr)
library(knitr)
library(kableExtra)
setwd("/Users/joyqiu/Documents/MediDSToolbox")
source("/Users/joyqiu/Documents/MediDSToolbox/shiny.R") # load tools from Joy's medical data science toolbox
rm(data_ml_demo, dict_ml_demo, data_org_demo, dict_org_demo,shiny_obj)
set.seed(333)
setwd("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/NIC/case/pas")
library(readxl)
data <- read_excel("./data/PAS Challenge Model Data.xlsx")
data_mdl <- assign.dict(data, get.dict(data))
data <- read_excel("./data/PAS Challenge Demographic Data.xlsx")
data_demo <- assign.dict(data, get.dict(data))
data <- read_excel("./data/PAS Challenge Cross-Validation Folds.xlsx")
data_cv <- assign.dict(data, get.dict(data))
data <- read_excel("./data/PAS Challenge Outcome Data.xlsx")
data_outc <- assign.dict(data, get.dict(data))
# merge data in one
data <- merge(data_mdl, data_outc, all=TRUE)
data <- merge(data, data_cv, all=TRUE)
data <- merge(data[,setdiff(colnames(data),"EGA")], data_demo, all=TRUE)
# must be data.frame type object before use dictionary functions
data <- as.data.frame(data)
# Create dictionary for data
data <- remove.dict(data)
data <- assign.dict(data, get.dict(data))
dict_data <- get.dict(data) # get a dictionary for this data
dict_data$type[which(dict_data$varname=="VitalID")] <- "key"
dict_data$unique_per_sbj[which(dict_data$varname=="VitalID")] <- TRUE
rownames(dict_data) <- NULL
res_dir <- "/Users/joyqiu/Documents/Documents JoyQiu Work/Research/NIC/case/pas/res/ridge/combined"
# ----- combined ------
# result directory
res_dir <- "/Users/joyqiu/Documents/Documents JoyQiu Work/Research/NIC/case/pas/res/ridge/combined"
# prepare data
c_col <- "VitalID"
y_col <- "Event"
x_cols <- setdiff(colnames(data_mdl),c_col)
x_cols <- c(x_cols[9:16], "Age",setdiff(colnames(data_demo),c_col))
df_mdl <- distinct(as.data.frame(data[,c("Fold", c_col, y_col, x_cols)]))
# # ----- demo only  ------
# # result directory
# res_dir <- "/Users/joyqiu/Documents/Documents JoyQiu Work/Research/NIC/case/pas/res/ridge/demo"
# # prepare data
# c_col <- "VitalID"
# y_col <- "Died"
# x_cols <- setdiff(colnames(data_demo),c_col)
# df_mdl <- distinct(as.data.frame(data[,c("Fold", c_col, y_col, x_cols)]))
# # ----- vital sign -----
# res_dir <- "/Users/joyqiu/Documents/Documents JoyQiu Work/Research/NIC/case/pas/res/ridge/continuous"
# # prepare data
# c_col <- "VitalID"
# y_col <- "Event"
# x_cols <- setdiff(colnames(data_mdl),c_col)
# x_cols <- c(x_cols[9:16], "Age")
# df_mdl <- distinct(as.data.frame(data[,c("Fold", c_col, y_col, x_cols)]))
# get paired dictionary
dict_mdl <- get.dict(df_mdl)
dict_mdl$type[which(dict_mdl$varname==c_col)] <- "key"
dict_mdl$unique_per_sbj[which(dict_mdl$varname%in%c("Fold", c_col, y_col))] <- TRUE
rownames(dict_mdl) <- NULL
# cluster by baby
c_label = dict_mdl$label[which(dict_mdl$varname==c_col)]
y_label = dict_mdl$label[which(dict_mdl$varname==y_col)]
x_labels_linear = dict_mdl$label[which(dict_mdl$type=="num")]
x_labels_linear = setdiff(x_labels_linear, c(y_label, c_label,"Fold"))
x_labels_tag = dict_mdl$label[which(dict_mdl$type=="fct"&dict_mdl$unit=="tag01")]
x_labels_tag = setdiff(x_labels_tag, c(y_label, c_label))
uni_obj <- front_uni_heatmap_group(data = df_mdl,
dict_data = dict_mdl,
num_labels = x_labels_linear,
y_label =  y_label,
cluster_label =  c_label,
layout_ncol = 3,
y_map_func=c("fold_risk", "probability", "log_odds")[1],
y_map_max=5,
method = "logit_rcs",
sample_per_cluster = NULL,
winsorizing = TRUE)
uni_obj$plot_obj_signat %>% ggsave(filename = paste0(res_dir,"/signature_illness.png"),width = 8,height = 10)
# get median list for variables
median_ls <- lapply(df_mdl[, x_labels_linear], function(x) {
return( median(x, na.rm = TRUE))
})
# median imputed
df_mdl[, x_labels_linear] <- lapply(df_mdl[, x_labels_linear], function(x) {
x[is.na(x)] <- median(x, na.rm = TRUE)
return(x)
})
if(!file.exists(paste0(res_dir,"/multi_full.RData"))){
x_labels_nonlin_rcs3 <- c("hr_std", "sp_max", "BirthHC", "hr_max", "hr_mean", "EGA", "BWT")
# feature selection
rm_vars <- c()
x_labels_tag <- setdiff(x_labels_tag,rm_vars)
x_labels_linear <- setdiff(x_labels_linear,rm_vars)
ridge_report <- front_multi_regression(
data = df_mdl,
dict_data = dict_mdl,
y_label = y_label,
cluster_label = c_label,
x_labels_linear = setdiff(x_labels_linear,x_labels_nonlin_rcs3),
x_labels_nonlin_rcs3 = x_labels_nonlin_rcs3,
x_labels_tag = x_labels_tag,
tune_by=c("logloss","auroc","aic","bic")[2],
return_performance = TRUE,
fold_idx_df_ex = data.frame("cluster_col" = df_mdl[,c_col], "fold" = df_mdl$Fold)
)
# # performance score table
# score_tbl <- ridge_report$devel_penal_trace_tbl
# cvAUC <- max(ridge_report$devel_penal_trace_tbl$AUROC,na.rm = TRUE)
#
# print(paste0("max cvauc = ", round(cvAUC,4)))
# kable(score_tbl[,c("penalty", "AUROC", "logloss", "AUPRC", "f1score", "AIC", "BIC")])
cvAUC <- max(ridge_report$devel_penal_trace_tbl$AUROC,na.rm = TRUE)
# final model object
model_obj <- ridge_report$devel_final_model_obj
# performance score table
score_tbl <- ridge_report$devel_penal_trace_tbl
# calibration curve
cali_plot_in <- ridge_report$perform_in_cali_plot
cali_plot_inorg <- ridge_report$perform_inorg_cali_plot
# permutation feature importance
permu_plot_in <- ridge_report$perform_in_scores_plot
permu_plot_in$data <- permu_plot_in$data %>% filter(score_by=="AUROC")
permu_plot_in$layers[[2]] <- NULL
# cv permutation feature importance
permu_cvdf <- ridge_report$model_obj$cv_obj$score_final_cv_permu
# trade off plots
tradeoff_plot_inorg <- ridge_report$perform_inorg_tradeoff_plot
tradeoff_plot_in <- ridge_report$perform_in_tradeoff_plot
# y hat dataframe
y_hat_inorg <- ridge_report$perform_inorg_df_hat # [-4*24,0]
y_hat_in <- ridge_report$perform_in_df_hat # [-12,0]
# tte plots
tte_plot_inorg <- ridge_report$perform_inorg_tte_plot
tte_plot_in <- ridge_report$perform_in_tte_plot
# scores in 10 folds
score_tbl_folds <- ridge_report$devel_cv_eval_trace_tbl
cv_yhat_df <- ridge_report$model_obj$cv_obj$cv_yhat_df
save(cvAUC,
model_obj,
score_tbl,
cali_plot_in,
cali_plot_inorg,
permu_plot_in,
permu_cvdf,
tradeoff_plot_inorg,
tradeoff_plot_in,
y_hat_inorg,
y_hat_in,
tte_plot_inorg,
tte_plot_in,
score_tbl_folds,
cv_yhat_df,
file = paste0(res_dir,"/multi_full.RData"))
}else{
load(paste0(res_dir,"/multi_full.RData"))
}
# anova chi-square
anova_df <- as.data.frame( plot(anova(model_obj), rm.totals=FALSE) )
colnames(anova_df) <- c("adjusted_chisq")
anova_df$varname <- rownames(anova_df)
anova_df$adjusted_chisq <- anova_df$adjusted_chisq - min(anova_df$adjusted_chisq, na.rm=TRUE)
anova_df$adjusted_chisq_prop <- anova_df$adjusted_chisq / anova_df$adjusted_chisq[which(anova_df$varname=="TOTAL")]
anova_df <- anova_df[which(!startsWith(anova_df$varname, "TOTAL")),c("varname", "adjusted_chisq_prop")]
anova_df$model <- "Ridge Regression"
rownames(anova_df) <- NULL
p_df <- as.data.frame( plot(anova(model_obj), what="P"))
colnames(p_df)<-"P"
p_df$varname <- row.names(p_df)
rownames(p_df) <- NULL
anova_df <- merge(anova_df, p_df, by="varname")
anova_df$p_value <- ifelse(anova_df$P<0.05, "p<0.05"," ")
anova_df_final <- anova_df
anova_df_final$varname <- stringr::str_to_lower( gsub("[^[:alnum:]]+"," ",anova_df_final$varname) )
anova_df_final$P <- round(anova_df_final$P, 4)
pdf <- permu_cvdf
pdf$model <- "Ridge Regression"
pdf$cvAUC <- cvAUC
pdf$varname <- gsub("permutate ", "",pdf$data)
pdf$varname <- stringr::str_to_lower( gsub("[^[:alnum:]]+"," ",pdf$varname) )
pdf <- merge(pdf, anova_df_final[,c("varname", "model", "p_value")], all.x=TRUE)
cvc_importance <- ggplot(pdf, aes(x=AUROC, y = tidytext::reorder_within(varname, -AUROC, model), color=p_value))+
geom_point() +
geom_vline(aes(xintercept = cvAUC)) +
scale_color_manual(values = c("p<0.05"="red")) +
scale_x_continuous(n.breaks = 5)+
tidytext::scale_y_reordered() +
facet_wrap(~model, scales = "free_y", ncol = 2) +
labs(y=NULL,x="\nAfter Permutation cvAUC", color = expression(paste(chi^{2}," test")))+
theme_bw()+
theme(plot.title = element_text(hjust = 0.5, face="bold", colour="black", size = 12),
axis.text.y = element_text(face="bold", colour="black", size=13),
axis.title.y = element_text(face="bold", colour="black", size=12),
axis.text.x = element_text(face="bold", colour="black", size=12),
axis.title.x = element_text(face="bold", colour="black", size=14),
legend.title = element_text(face="bold", colour="black", size=12),
legend.text = element_text(face="bold", colour="black", size=10),
legend.position = "bottom",
strip.text.x = element_text(face="bold", colour="black", size=12))
cvc_importance %>% ggsave(filename = paste0(res_dir,"/cvc_importance_full.png"),width = 6,height=7, bg="white")
if(!file.exists(paste0(res_dir,"/multi.RData"))){
x_labels_nonlin_rcs3 <- c("hr_std", "sp_max", "BirthHC", "hr_max", "hr_mean", "EGA", "BWT")
# feature selection
rm_vars <- c("Hispanic","Steroids","White","InBorn","Vaginal","C_section","Black", "Apgar1")
x_labels_tag <- setdiff(x_labels_tag,rm_vars)
x_labels_linear <- setdiff(x_labels_linear,rm_vars)
ridge_report <- front_multi_regression(
data = df_mdl,
dict_data = dict_mdl,
y_label = y_label,
cluster_label = c_label,
x_labels_linear = setdiff(x_labels_linear,x_labels_nonlin_rcs3),
x_labels_nonlin_rcs3 = x_labels_nonlin_rcs3,
x_labels_tag = x_labels_tag,
tune_by=c("logloss","auroc","aic","bic")[2],
return_performance = TRUE,
fold_idx_df_ex = data.frame("cluster_col" = df_mdl[,c_col], "fold" = df_mdl$Fold)
)
# # performance score table
# score_tbl <- ridge_report$devel_penal_trace_tbl
# cvAUC <- max(ridge_report$devel_penal_trace_tbl$AUROC,na.rm = TRUE)
#
# print(paste0("max cvauc = ", round(cvAUC,4)))
# kable(score_tbl[,c("penalty", "AUROC", "logloss", "AUPRC", "f1score", "AIC", "BIC")])
cvAUC <- max(ridge_report$devel_penal_trace_tbl$AUROC,na.rm = TRUE)
# final model object
model_obj <- ridge_report$devel_final_model_obj
# performance score table
score_tbl <- ridge_report$devel_penal_trace_tbl
# calibration curve
cali_plot_in <- ridge_report$perform_in_cali_plot
cali_plot_inorg <- ridge_report$perform_inorg_cali_plot
# permutation feature importance
permu_plot_in <- ridge_report$perform_in_scores_plot
permu_plot_in$data <- permu_plot_in$data %>% filter(score_by=="AUROC")
permu_plot_in$layers[[2]] <- NULL
# cv permutation feature importance
permu_cvdf <- ridge_report$model_obj$cv_obj$score_final_cv_permu
# trade off plots
tradeoff_plot_inorg <- ridge_report$perform_inorg_tradeoff_plot
tradeoff_plot_in <- ridge_report$perform_in_tradeoff_plot
# y hat dataframe
y_hat_inorg <- ridge_report$perform_inorg_df_hat # [-4*24,0]
y_hat_in <- ridge_report$perform_in_df_hat # [-12,0]
# tte plots
tte_plot_inorg <- ridge_report$perform_inorg_tte_plot
tte_plot_in <- ridge_report$perform_in_tte_plot
# scores in 10 folds
score_tbl_folds <- ridge_report$devel_cv_eval_trace_tbl
cv_yhat_df <- ridge_report$model_obj$cv_obj$cv_yhat_df
save(cvAUC,
model_obj,
score_tbl,
cali_plot_in,
cali_plot_inorg,
permu_plot_in,
permu_cvdf,
tradeoff_plot_inorg,
tradeoff_plot_in,
y_hat_inorg,
y_hat_in,
tte_plot_inorg,
tte_plot_in,
score_tbl_folds,
cv_yhat_df,
file = paste0(res_dir,"/multi.RData"))
}else{
load(paste0(res_dir,"/multi.RData"))
}
# anova chi-square
anova_df <- as.data.frame( plot(anova(model_obj), rm.totals=FALSE) )
colnames(anova_df) <- c("adjusted_chisq")
anova_df$varname <- rownames(anova_df)
anova_df$adjusted_chisq <- anova_df$adjusted_chisq - min(anova_df$adjusted_chisq, na.rm=TRUE)
anova_df$adjusted_chisq_prop <- anova_df$adjusted_chisq / anova_df$adjusted_chisq[which(anova_df$varname=="TOTAL")]
anova_df <- anova_df[which(!startsWith(anova_df$varname, "TOTAL")),c("varname", "adjusted_chisq_prop")]
anova_df$model <- "Ridge Regression"
rownames(anova_df) <- NULL
p_df <- as.data.frame( plot(anova(model_obj), what="P"))
colnames(p_df)<-"P"
p_df$varname <- row.names(p_df)
rownames(p_df) <- NULL
anova_df <- merge(anova_df, p_df, by="varname")
anova_df$p_value <- ifelse(anova_df$P<0.05, "p<0.05"," ")
anova_df_final <- anova_df
anova_df_final$varname <- stringr::str_to_lower( gsub("[^[:alnum:]]+"," ",anova_df_final$varname) )
anova_df_final$P <- round(anova_df_final$P, 4)
pdf <- permu_cvdf
pdf$model <- "Ridge Regression"
pdf$cvAUC <- cvAUC
pdf$varname <- gsub("permutate ", "",pdf$data)
pdf$varname <- stringr::str_to_lower( gsub("[^[:alnum:]]+"," ",pdf$varname) )
pdf <- merge(pdf, anova_df_final[,c("varname", "model", "p_value")], all.x=TRUE)
cvc_importance <- ggplot(pdf, aes(x=AUROC, y = tidytext::reorder_within(varname, -AUROC, model), color=p_value))+
geom_point() +
geom_vline(aes(xintercept = cvAUC)) +
scale_color_manual(values = c("p<0.05"="red")) +
scale_x_continuous(n.breaks = 5)+
tidytext::scale_y_reordered() +
facet_wrap(~model, scales = "free_y", ncol = 2) +
labs(y=NULL,x="\nAfter Permutation cvAUC", color = expression(paste(chi^{2}," test")))+
theme_bw()+
theme(plot.title = element_text(hjust = 0.5, face="bold", colour="black", size = 12),
axis.text.y = element_text(face="bold", colour="black", size=13),
axis.title.y = element_text(face="bold", colour="black", size=12),
axis.text.x = element_text(face="bold", colour="black", size=12),
axis.title.x = element_text(face="bold", colour="black", size=14),
legend.title = element_text(face="bold", colour="black", size=12),
legend.text = element_text(face="bold", colour="black", size=10),
legend.position = "bottom",
strip.text.x = element_text(face="bold", colour="black", size=12))
cvc_importance %>% ggsave(filename = paste0(res_dir,"/cvc_importance.png"),width = 6,height=7, bg="white")
tradeoff_plot_inorg %>% ggsave(filename = paste0(res_dir,"/trade_offs.png"),width=8,height=3, bg="white")
cali_plot_inorg <- cali_plot_inorg + theme_bw()
cali_plot_inorg %>% ggsave(filename = paste0(res_dir,"/cali.png"),width=3,height=3, bg="white")
print(cvAUC)
library(readxl)
data <- read_excel("./data/Test Model Data.xlsx")
data_mdl <- assign.dict(data, get.dict(data))
data <- read_excel("./data/Test Demographic Data.xlsx")
data_demo <- assign.dict(data, get.dict(data))
# merge data in one
data <- merge(data_mdl[,setdiff(colnames(data_mdl),"EGA")], data_demo, all=TRUE)
# must be data.frame type object before use dictionary functions
data <- as.data.frame(data)
# Create dictionary for data
data <- remove.dict(data)
data <- assign.dict(data, get.dict(data))
dict_data <- get.dict(data) # get a dictionary for this data
dict_data$type[which(dict_data$varname=="VitalID")] <- "key"
dict_data$unique_per_sbj[which(dict_data$varname=="VitalID")] <- TRUE
rownames(dict_data) <- NULL
new_data <- data
new_dict_data <- dict_data
# median imputed
# Perform median imputation
for (var_name in names(median_ls)) {
if (var_name %in% names(new_data)) {
# Replace NA in new_data with the median value from median_values
new_data[[var_name]][is.na(new_data[[var_name]])] <- median_ls[[var_name]]
}
}
test_y <- rms::predictrms(model_obj, newdata = new_data)
write.csv( data.frame(p = 1/(1+exp(-test_y))), paste0(res_dir,"/test_p.csv"),row.names = F)
print(cvAUC)
# setwd(dirname(rstudioapi::getSourceEditorContext()$path))
rm(list = ls())
library(dplyr)
library(rslurm)
library(Matrix)
library(lme4)
library(MASS)
library(pROC)
list.of.packages <- c("dplyr",
"rslurm",
"MASS",
"lme4",
"Matrix",
"pROC")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, lib = "/sfs/qumulo/qhome/jq2uw/R/goolf/4.3")
source("./sim_functions.R")
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
rm(list = ls())
library(dplyr)
library(rslurm)
library(Matrix)
library(lme4)
library(MASS)
library(pROC)
list.of.packages <- c("dplyr",
"rslurm",
"MASS",
"lme4",
"Matrix",
"pROC")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, lib = "/sfs/qumulo/qhome/jq2uw/R/goolf/4.3")
source("./sim_functions.R")
path = paste0("./nic_utils")
flst = list.files( path)
sapply(c(paste(path,flst,sep="/")), source, .GlobalEnv)
# Parameters
n_cluster <- c(50, 100) # number of clusters
n_obs_per_cluster <- c(5, 10, 30, 50, 80) # number of observations per cluster
n_ttl_betas <- seq(3, 15) # number of total effects
fix_rdm_ratio <- c(0.2, 0.5, 0.8) # proportion of fix effects
# Parameters
n_cluster <- c(50, 100) # number of clusters
n_obs_per_cluster <- c(5, 10, 30, 50, 80) # number of observations per cluster
n_ttl_betas <- seq(3, 15) # number of total effects
fix_rdm_ratio <- c(0.2, 0.5, 0.8) # proportion of fix effects
sigma_fix <- c(3,5,10)
sigma_rdm_fix_ratio <- c(0.2, 0.5, 0.8)
# Define the simulation conditions
param_grid <- expand.grid(n_cluster = n_cluster,
n_obs_per_cluster = n_obs_per_cluster,
n_ttl_betas = n_ttl_betas,
fix_rdm_ratio = fix_rdm_ratio,
sigma_fix = sigma_fix,
sigma_rdm_fix_ratio = sigma_rdm_fix_ratio )
simulation_conditions <- as.data.frame(param_grid)
simulation_conditions$id <- seq(1:nrow(param_grid))
simulation_conditions$iter <- 100
sim_condition = simulation_conditions[which(simulation_conditions$id==1),]
# setwd(dirname(rstudioapi::getSourceEditorContext()$path))
rm(list = ls())
library(dplyr)
library(rslurm)
library(Matrix)
library(lme4)
library(MASS)
library(pROC)
list.of.packages <- c("dplyr",
"rslurm",
"MASS",
"lme4",
"Matrix",
"pROC")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, lib = "/sfs/qumulo/qhome/jq2uw/R/goolf/4.3")
source("./sim_functions.R")
path = paste0("./nic_utils")
flst = list.files( path)
sapply(c(paste(path,flst,sep="/")), source, .GlobalEnv)
# Parameters
n_cluster <- c(50, 100) # number of clusters
n_obs_per_cluster <- c(5, 10, 30, 50, 80) # number of observations per cluster
n_ttl_betas <- seq(3, 15) # number of total effects
fix_rdm_ratio <- c(0.2, 0.5, 0.8) # proportion of fix effects
sigma_fix <- c(3,5,10)
sigma_rdm_fix_ratio <- c(0.2, 0.5, 0.8)
# Define the simulation conditions
param_grid <- expand.grid(n_cluster = n_cluster,
n_obs_per_cluster = n_obs_per_cluster,
n_ttl_betas = n_ttl_betas,
fix_rdm_ratio = fix_rdm_ratio,
sigma_fix = sigma_fix,
sigma_rdm_fix_ratio = sigma_rdm_fix_ratio )
simulation_conditions <- as.data.frame(param_grid)
simulation_conditions$id <- seq(1:nrow(param_grid))
simulation_conditions$iter <- 100
sim_condition = simulation_conditions[which(simulation_conditions$id==1),]
results_list = list()
for(i in 1:sim_condition$iter){
tryCatch({
res <- generate_data(sim_condition$n_cluster,
sim_condition$n_obs_per_cluster,
sim_condition$n_ttl_betas,
sim_condition$fix_rdm_ratio,
sim_condition$sigma_fix,
sim_condition$sigma_rdm_fix_ratio)
# ground truth mixed effect model
m0 <- fit_glmer(y = res$y,
c = res$c,
data = res$data)
# lr model evaluation matrices
m1 <- eval_glm(y = res$y,
c = res$c,
data = res$data)
stopifnot(!is.na(m1$aic))
# measure bias
bias <- calculate_bias(res, m0, m1)
results_list[[i]] = list(id = sim_condition$id,
iter = i,
bias0 = bias$bias0,
bias1 = bias$bias1,
aic = m1$aic,
bic = m1$bic,
nic = m1$nic,
dev = m1$deviance,
looauc = m1$looAUC,
loodev = m1$looDeviance)
}, error = function(e){
print(e)
print(paste0("skip iteration ",i))
})
}
results_list <- Filter(function(x) !is.null(x), results_list)
toReturn = do.call("rbind", results_list)
toReturn
View(toReturn)
